{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9rigx9lYp0r"
   },
   "source": [
    "***\n",
    "# EDA for tweet_emotions.csv dataset\n",
    "https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1 Load the dataset\n",
    " <span style=\"color:red\">!!!Make sure to comment out the correct source (Google drive or local)!!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9j2cEQQtYMBR",
    "outputId": "6f2ae201-8489-40f7-cefd-8d0715350d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
      "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# read from the google drive\n",
    "# url = 'https://drive.google.com/file/d/1xv5hff4DntWz6gn4KMXkBQ6t5_Vs16MQ/view?usp=sharing'\n",
    "# url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "# read from local\n",
    "url = '../datasets/tweet_emotions.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2 Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes for each of the columns in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id      int64\n",
      "sentiment    object\n",
      "content      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique types and count of sentiments in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count  percentage\n",
      "neutral      8638     21.5950\n",
      "worry        8459     21.1475\n",
      "happiness    5209     13.0225\n",
      "sadness      5165     12.9125\n",
      "love         3842      9.6050\n",
      "surprise     2187      5.4675\n",
      "fun          1776      4.4400\n",
      "relief       1526      3.8150\n",
      "hate         1323      3.3075\n",
      "empty         827      2.0675\n",
      "enthusiasm    759      1.8975\n",
      "boredom       179      0.4475\n",
      "anger         110      0.2750\n"
     ]
    }
   ],
   "source": [
    "# get the value counts of each unique value\n",
    "counts = df['sentiment'].value_counts()\n",
    "\n",
    "# convert the counts to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "cp_df = pd.DataFrame({'count': counts, 'percentage': percentages})\n",
    "\n",
    "print(cp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max and min lengths of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length: 167\n",
      "Minimum length: 1\n"
     ]
    }
   ],
   "source": [
    "lengths = df['content'].str.len()\n",
    "\n",
    "# display the maximum and minimum lengths\n",
    "print('Maximum length:', lengths.max())\n",
    "print('Minimum length:', lengths.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3 Check each sentiment to see what type of content there is to see if it's legit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to explore the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the emotion and number of random tweets to see\n",
    "def explore(emotion=None, num_tweets=5):\n",
    "    if emotion == None:\n",
    "        return 'no emotion provided'\n",
    "    elif emotion not in all_sentiments:\n",
    "        return 'not one of the sentiments in the dataframe'\n",
    "    else:\n",
    "        content = df.loc[df['sentiment'] == emotion, 'content']\n",
    "\n",
    "        random_nums = random.sample(range(len(content)), num_tweets)\n",
    "        \n",
    "        print(f\"Number of tweets for '{emotion}': {len(content)}\")\n",
    "        print(f\"Percentage of the dataset: {cp_df.loc[emotion].percentage}\")\n",
    "        print(f\"Random indices:' {random_nums}\", end='\\n\\n')\n",
    "        print(f\"Random {num_tweets} Tweets for emotion '{emotion}':\")\n",
    "\n",
    "        counter = 1\n",
    "        for tweet in content.iloc[random_nums]:\n",
    "            print(f\"{counter}: {tweet}\", end='\\n')\n",
    "            counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'boredom', 'empty', 'enthusiasm', 'fun', 'happiness', 'hate', 'love', 'neutral', 'relief', 'sadness', 'surprise', 'worry']\n"
     ]
    }
   ],
   "source": [
    "all_sentiments = sorted(df['sentiment'].unique())\n",
    "print(all_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell prints all of the sentiments all at once,\n",
    "# but keeping it commented out for now\n",
    "\n",
    "# unique_sentiments = df['sentiment'].unique()\n",
    "\n",
    "# for emotion in unique_sentiments:\n",
    "#     explore(emotion)\n",
    "#     print('**********************************************************\\n**********************************************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'anger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'anger': 110\n",
      "Percentage of the dataset: 0.27499999999999997\n",
      "Random indices:' [25, 37, 81, 103, 19]\n",
      "\n",
      "Random 5 Tweets for emotion 'anger':\n",
      "1: Shout out to my moms for wakin me up so prematurely! Preciate it\n",
      "2: Very bad things.......I need to stop thinking!\n",
      "3: Sitting in traffic while my car gets rained on. Just washed it on Sunday. Doesn't the weather know this is California?\n",
      "4: @brainofdane DUDE.  You're a hax0r!!!1!  You should put Final Cut Pro on there and tell me how stable it is\n",
      "5: Confuzzled\n"
     ]
    }
   ],
   "source": [
    "explore('anger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'anger':\n",
    "\n",
    "The number of 'anger' tweets, 110, is the lowest count in the dataset and represents just 0.2750% of the dataset. This will lead to an imbalance issue.<br>\n",
    "<br>\n",
    "Some of these Tweets seem to be mislabeled (e.g. \"omg! goooood ass nappy nap  jusss woke up bout 2 clean up a lil then get ready\", \"OIL IS CHANGED!  And I am filthy.    But it's an accomplished filthy.\", \"Just sittin here waitin for my coffee to be full grown on farm town before going to bed\"). But most seem to be labeled correctly (e.g. \"What did I do to you!  sheesh\", \"The &quot;Catch Me If You Can&quot; DVD that I rented from Blockbuster.com yesterday was cracked. Figured it out about 35 minutes into the movie.\", \"@drakesizzle  If you don't want to come then don't come. JEEEEEZ.\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'boredom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'boredom': 179\n",
      "Percentage of the dataset: 0.4475\n",
      "Random indices:' [55, 21, 0, 172, 19]\n",
      "\n",
      "Random 5 Tweets for emotion 'boredom':\n",
      "1: @shaveblog Problem is, Flash isnt GPU accelerated.  The Atom 330 can't play Youtube HD or Hulu HD fullscreen   Big deal with Plex...\n",
      "2: Again documentation day\n",
      "3: i'm so tired\n",
      "4: 1:36 AM screw it im going to bed... one love\n",
      "5: @solobasssteve I'm with you there - filing is so much less fun than sorting cos you still have to look at it &amp; hunt down details\n"
     ]
    }
   ],
   "source": [
    "explore('boredom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'boredom':\n",
    "\n",
    "This is the second lowest sentiment category with only 179 Tweets representing 0.4475% of the dataset. Like anger, this will be an imbalance issue.<br>\n",
    "<br>\n",
    "The interpretation of 'bored' seems to vary from the traditional sense (e.g. \"I am sooooooo bored in textiles !\", \"is bored. my BFF doesn't want to hang out\") to \"this person must be bored because they have nothing better to do than write this Tweet\" (e.g. \"aw now where's that little asian girl who runs round pooping her pants in public? i miss laughing at her.\", \"my neighbours are far too loud in thier back garden, all I can hear is this loud woman that won't stop laughing\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'empty': 827\n",
      "Percentage of the dataset: 2.0675\n",
      "Random indices:' [579, 98, 308, 567, 257]\n",
      "\n",
      "Random 5 Tweets for emotion 'empty':\n",
      "1: @dougiemcfly Hi Dougie I'm your fan from Thailand. I'm Film 'Luv ur song so much\n",
      "2: really hates delayed trains especially 44 minute delayed trains. Now going to be late for work\n",
      "3: @CarrieStephens mine do it no matter WHO i'm on the phone with!\n",
      "4: @pratikjain4 welcome\n",
      "5: @PinkTribble I do not consider myself to be an estate agent\n"
     ]
    }
   ],
   "source": [
    "explore('empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'empty'\n",
    "\n",
    "It seems that the 'empty' sentiment is very random. At times, there are two or more sentiments expressed (e.g. \"back from grimsby  it sucks bein back but was amazin wknd anyway!!\"). Other times they are just statements of fact or questions (e.g. \"On the way to santa monica\", \"@spook68 morning.any plans for today?\"). Still other times they are just words (\"HELLOO\"). Sometimes, there are Tweets that seem like they should be labeled with one of the other emotions (e.g. \"yay, joss is coming over on saturday\" should probably be labeled 'happiness' or 'enthusiasm') and perhaps because there are possibly two different labels in that last example, the labeler chose to leave it empty.<br>\n",
    "<br>\n",
    "There are 827 of the 'empty' Tweets representing 2.0675% of the dataset. We should consider removing these from the dataset since these seem to be the \"unknown\" type of Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'enthusiasm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'enthusiasm': 759\n",
      "Percentage of the dataset: 1.8975\n",
      "Random indices:' [79, 729, 164, 77, 717]\n",
      "\n",
      "Random 5 Tweets for emotion 'enthusiasm':\n",
      "1: Just been out to try to catch a swarm, gone into a roof gable end   Set up a bait hive an hoping for the best at the moment\n",
      "2: Hour til lunch, can't wait. Ima go to Mcd's\n",
      "3: last day of work  ...but everyone is making it so great!\n",
      "4: Just got up. Need to leave for class in a hour.\n",
      "5: awake and ready to learn a little more\n"
     ]
    }
   ],
   "source": [
    "explore('enthusiasm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'enthusiasm':\n",
    "\n",
    "These set of Tweets also suffer from some mislabeling issues (e.g. \"I'm bored, extremely bored. in the car. waiting for my dad. and dinner. chinese. yummm.\", \"wishes I could be the one going to our conference in the Bahamas next week\"). Some Tweets seemed to be mislabeled as 'enthusiasm' due to certain keywords (e.g. \"I made my parents add u guys on the family myspace...they were impressed by the song\" -- 'impressed') or perhaps the number of exclamantion points (e.g. \"im so new!! and i need ur help\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'fun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'fun': 1776\n",
      "Percentage of the dataset: 4.44\n",
      "Random indices:' [1270, 811, 645, 1743, 120, 1611, 503, 957, 1347, 971, 1219, 1639, 192, 552, 1700, 538, 352, 526, 1594, 877, 1345, 1055, 1162, 1394, 163, 1475, 1454, 1097, 1727, 1195, 259, 1732, 1654, 762, 1683, 1609, 200, 970, 1647, 698, 773, 456, 1407, 1091, 1263, 696, 1227, 303, 86, 782]\n",
      "\n",
      "Random 50 Tweets for emotion 'fun':\n",
      "1: @__Greer__ Hey Greer! I'm Marco! It's nice to talk with a fellow actor(ress) haha\n",
      "2: @quinland  Yeah It Good But dont Click The Red X Because It Shuts It Down But Other Then That Its Good  And When U minimize It , It Goes..\n",
      "3: lm @ TGI Fridays on a Monday.. Hee hee!\n",
      "4: Is playing bubblewrap on her iPhone. Over and over and over again. Still, beats working...\n",
      "5: really wanted to go to that gig tonight\n",
      "6: Getting ready to go study outside while having some fun in such a nice sunny day.\n",
      "7: @miss_tattoo Hey girl. I'm a new follower - I think it's awesome you've gotten the chance to get so close to Donnie. Very cool!!\n",
      "8: @Perpetual_Kid May the 4th be with you\n",
      "9: That was a fun show. Grabbing a bite to eat now.\n",
      "10: @dayzie63 LMï¿½ï¿½oï¿½o! my job is funn\n",
      "11: @Candice_Jo you'll have a drink bc the race is over...I'm telling you,it's an addiction that leads to Elvis presiding over our wedding\n",
      "12: I always forget how much fun kyle is!\n",
      "13: @jpl1953 - Sorry only just seen this - how strange it seems only to happen from my iPhone - perhaps it is a problem with Twitterific\n",
      "14: downloading songs while trying to sneak a lil homework in too, which should be my main priority not songs lol\n",
      "15: @GayAdoptionDad please do  I'll settle for cheap cider for meeting deadline. Have you seen our new blog at www.havealovelytime.com?\n",
      "16: @thunderror U can play as ur avatar (1st person) *or* as his team member (3rd person). Battles implement real-time strategy. AoE style.\n",
      "17: @themaguire maybe one day I can be on your favorite producers list  lol\n",
      "18: @robbcox that made me laugh.  Sorry Grets, but you are not going to the Pool Room.\n",
      "19: http://twitpic.com/4wqfv - dark berry mocha frapp.. heaven.. TRY IT EVERYONE!!  here.. let me pass it to you\n",
      "20: @jlovely crossing my fingers for ya! &amp; hey you'll be on my side of town!  Welcome! LOL\n",
      "21: Waiting to go to bed. Had a great weekend\n",
      "22: @Malunis A couple of other guys did similar mods, so it may not have been mine that @Artoni saw. I think mine's the best, but I'm biased\n",
      "23: Gonna go drop some logs in the pool  back in 15 min\n",
      "24: excited to see my cousins this week.\n",
      "25: @tommcfly I really hope you see my tweets. Sent you so much, I swear. Do a tour in the Philippines, please?  *prays*\n",
      "26: Wow.... I thought we'd only be gaming for 8 hours but here I am 13 hours later seeing the last person out. &lt;_&lt; Long session, but fun.\n",
      "27: Dancing in the rain makes of complete\n",
      "28: @miizronnie aha speaking German  haha maybe i should send some stuff in Italian ;)\n",
      "29: derby day! woooo, come on UNITED!\n",
      "30: Taking the dog on a walk..the weather is perfect rite now  @patty_p sucks becuz she didn't come with me hahaha\n",
      "31: Trying to sell my GM stock\n",
      "32: @ansje_44 Thanks!! It was a bit out of my comfort zone but it was fun\n",
      "33: Still awake lol Finished talking to a really good Brawl player. We talking in SmashSpace.ning.com  Join the website if you like SSBB!\n",
      "34: Yea running on 3 hours. Lets do this test\n",
      "35: @Celebritymound peep this remix from &quot;The Wu Dynasty&quot; remix tape its delayed but this will give u a idea\n",
      "36: @billingtonart think gone enjoy the beautyy of the nature , maybe sit down anywhere and write a little ,just trying to finish my last pic\n",
      "37: The first officially beautiful day of the year and I'm stuck inside the office    A Magners and BBQ will make up for it!\n",
      "38: why me? i am about to read another ecology book for two hours. its all good fun today\n",
      "39: @forkncork I'll be thinking about how many goals United are going to knock past City. How 'bout you?\n",
      "40: @TheRealGinuwine ... thx for ur msg, so awesome!  luv the new single! xoxo\n",
      "41: working from home office today and catching up on everything except twitter\n",
      "42: @funkylovin ah mine is never home before 8   I handed off the kids and grabbed the bottle of malibu and a coke..momma getting drinky :para\n",
      "43: is about to go buy his mother a mother's day gift\n",
      "44: http://twitpic.com/4w7d2 bwahahahahahaha I am so awesome\n",
      "45: Snoops uncle who was the COOLEST dancer EVER!!!!!!  http://twitpic.com/4wfqn\n",
      "46: Rode a jeep home with my mentor. Heard his story being in UP FineArts. Pretty cool.\n",
      "47: Goin to drive-in movie for the first time\n",
      "48: have an extra Justin Rutledge ticket for the Mod Club tonight\n",
      "49: ready for a very busy, FUN day tomorrow! gotta keep myself busy when my lover is gone\n",
      "50: @protoslag - well, look who's tweeting.\n"
     ]
    }
   ],
   "source": [
    "explore('fun', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'fun':\n",
    "\n",
    "This emotion is a bit hard to nail down in terms of what the labelers were going. And, as in other emotions, it seems that there are a lot of mislabeled Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'happiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'happiness':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'hate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('hate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'hate':\n",
    "\n",
    "There are 1132 Tweets labeled 'hate'. They seem to strongly resemble 'anger' and can possibly be relabeled as such. In so doing, we would increase the number of 'anger' Tweets to help with the imbalance issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'love':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'neutral':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'relief'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('relief')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'relief':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('sadness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'sadness':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('surprise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'surprise':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'worry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('worry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'worry':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General thoughts about the contents of these tweets:\n",
    "\n",
    "There are @mentions, URLs, and character entities (\"\\&nbsp;\", \"\\&quot;\", \"\\&amp;\") that we may want to remove as part of data cleaning since they are superfluous in terms of indicating emotion. There are also hashtags that we may or may not consider removing. Some of these hashtags don't actually add to the sentiment, but some do so we may consider keeping them.<br>\n",
    "<br>\n",
    "Additionally, there are multiple emotions that have a proportionally small amount of records when compared to others ('anger' with 110 records and 'neutral' with 8638). We will have to deal with this somehow, perhaps by using stratified sampling techniquest (https://stackoverflow.com/questions/70849127/training-validation-and-test-sets-for-imbalanced-datasets-in-machine-learning) rather than a random train/test/validation split which may overrepresent the 'neutral' emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4 Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any @mentions from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove @mentions from the 'content' column\n",
    "df['content'] = df['content'].str.replace(r'@\\w+', '')\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any whitespace from the front and end of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.strip()\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
