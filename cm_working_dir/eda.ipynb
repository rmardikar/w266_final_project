{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9rigx9lYp0r"
   },
   "source": [
    "***\n",
    "# EDA for tweet_emotions.csv dataset\n",
    "https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1 Load the dataset\n",
    " <span style=\"color:red\">!!!Make sure to comment out the correct source (Google drive or local)!!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9j2cEQQtYMBR",
    "outputId": "6f2ae201-8489-40f7-cefd-8d0715350d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
      "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# read from the google drive\n",
    "# url = 'https://drive.google.com/file/d/1xv5hff4DntWz6gn4KMXkBQ6t5_Vs16MQ/view?usp=sharing'\n",
    "# source = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "# read from local\n",
    "source = '../datasets/tweet_emotions.csv'\n",
    "\n",
    "df = pd.read_csv(source)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2 Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes for each of the columns in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id      int64\n",
      "sentiment    object\n",
      "content      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique types and count of sentiments in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count  percentage\n",
      "neutral      8638     21.5950\n",
      "worry        8459     21.1475\n",
      "happiness    5209     13.0225\n",
      "sadness      5165     12.9125\n",
      "love         3842      9.6050\n",
      "surprise     2187      5.4675\n",
      "fun          1776      4.4400\n",
      "relief       1526      3.8150\n",
      "hate         1323      3.3075\n",
      "empty         827      2.0675\n",
      "enthusiasm    759      1.8975\n",
      "boredom       179      0.4475\n",
      "anger         110      0.2750\n"
     ]
    }
   ],
   "source": [
    "# get the value counts of each unique value\n",
    "counts = df['sentiment'].value_counts()\n",
    "\n",
    "# convert the counts to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "cp_df = pd.DataFrame({'count': counts, 'percentage': percentages})\n",
    "\n",
    "print(cp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max and min lengths of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length: 167\n",
      "Minimum length: 1\n"
     ]
    }
   ],
   "source": [
    "lengths = df['content'].str.len()\n",
    "\n",
    "# display the maximum and minimum lengths\n",
    "print('Maximum length:', lengths.max())\n",
    "print('Minimum length:', lengths.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3 Check each sentiment to see what type of content there is to see if it's legit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to explore the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the emotion and number of random tweets to see\n",
    "def explore(emotion=None, num_tweets=5):\n",
    "    if emotion == None:\n",
    "        return 'no emotion provided'\n",
    "    elif emotion not in all_sentiments:\n",
    "        return 'not one of the sentiments in the dataframe'\n",
    "    else:\n",
    "        content = df.loc[df['sentiment'] == emotion, 'content']\n",
    "\n",
    "        random_nums = random.sample(range(len(content)), num_tweets)\n",
    "        \n",
    "        print(f\"Number of tweets for '{emotion}': {len(content)}\")\n",
    "        print(f\"Percentage of the dataset: {cp_df.loc[emotion].percentage}\")\n",
    "        print(f\"Random indices: {random_nums}\", end='\\n\\n')\n",
    "        print(f\"Random {num_tweets} Tweets for emotion '{emotion}':\")\n",
    "\n",
    "        counter = 1\n",
    "        for tweet in content.iloc[random_nums]:\n",
    "            print(f\"{counter}: {tweet}\", end='\\n')\n",
    "            counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'boredom', 'empty', 'enthusiasm', 'fun', 'happiness', 'hate', 'love', 'neutral', 'relief', 'sadness', 'surprise', 'worry']\n"
     ]
    }
   ],
   "source": [
    "all_sentiments = sorted(df['sentiment'].unique())\n",
    "print(all_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'anger': 110\n",
      "Percentage of the dataset: 0.27499999999999997\n",
      "Random indices: [97, 88, 51, 58, 40]\n",
      "\n",
      "Random 5 Tweets for emotion 'anger':\n",
      "1: @rockchick0125 yup!  Now I can join in on the nin access fun!\n",
      "2: @stevebiddle I used to be - but that was a while ago now - your argument is pretty sound for a trolley pusher\n",
      "3: #thingsmummysaid my mummy told me she never wnted to be my mummy ever again  so i live wid my dad i think ?? it all confusing\n",
      "4: My throat is on fire\n",
      "5: The &quot;Catch Me If You Can&quot; DVD that I rented from Blockbuster.com yesterday was cracked. Figured it out about 35 minutes into the movie.\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'boredom': 179\n",
      "Percentage of the dataset: 0.4475\n",
      "Random indices: [77, 36, 129, 57, 97]\n",
      "\n",
      "Random 5 Tweets for emotion 'boredom':\n",
      "1: it's realy boo0o0o0o00oring ..my book is on the side &amp; i'm not studyin for sure...\n",
      "2: I am sooooooo bored in textiles !\n",
      "3: Just started feeling bad again  ugh. I hate it when I don't feel good!!\n",
      "4: @BlueEyedGirl18 One hour and fifteen minutes.  A dreadful wait.\n",
      "5: @ericmaglio1 i have no phone  whatchu doing tonight sucka. no dane cook she sold the tickets. lamee.\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'empty': 827\n",
      "Percentage of the dataset: 2.0675\n",
      "Random indices: [19, 691, 212, 676, 69]\n",
      "\n",
      "Random 5 Tweets for emotion 'empty':\n",
      "1: I came with a q: &quot;any recommended hairdresser? U r full and they suggested me to others  &quot; His ego talked and I'm in d line\n",
      "2: feels sickly. i need a personal assistant to keep fast food away from me! any takers?\n",
      "3: I forgot to complain about Southwest not doing preboard for families any more.  Was the worst part of travelling\n",
      "4: @mileycyrus when u get a chance can u post a video of tinkerbell saying peekaboo i kinda wana hear him say it\n",
      "5: headed to the hospital. i can't take the pain anymore\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'enthusiasm': 759\n",
      "Percentage of the dataset: 1.8975\n",
      "Random indices: [620, 91, 532, 167, 653]\n",
      "\n",
      "Random 5 Tweets for emotion 'enthusiasm':\n",
      "1: @officialTila who you snugglin with Tila???\n",
      "2: baby i need you , right here , right now\n",
      "3: @Lawrence_n_DC amendment 4.5: the right to be big pimpin? Because gotta say, a positive right at best. Man, 2nd time tonight w/ this thrd\n",
      "4: @mitchelmusso I want to call you but it would cost to much  But Maybe my parents will say okay =D\n",
      "5: Shite night, tomorow, I get to hang out with my little brother and neice, should be sufficient enough to change my mood\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'fun': 1776\n",
      "Percentage of the dataset: 4.44\n",
      "Random indices: [414, 535, 966, 935, 825]\n",
      "\n",
      "Random 5 Tweets for emotion 'fun':\n",
      "1: acsvxdcbgfn soccer now. shall see young phoebe after D: I don't want her dressed up though\n",
      "2: @foxmarta Look forward to seeing the resume!\n",
      "3: @nickdaigle too short as usual...  but was awesome\n",
      "4: @spitphyre arre seriously! They shud take his sperm nd clone him into 23 yr old single guys\n",
      "5: what a great day for a massage! book your appointment today  617-262-2220\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'happiness': 5209\n",
      "Percentage of the dataset: 13.0225\n",
      "Random indices: [3359, 914, 2313, 320, 4958]\n",
      "\n",
      "Random 5 Tweets for emotion 'happiness':\n",
      "1: @courseofhistory Vancouver, so classy.  #canucks\n",
      "2: @DavidArchie I'm watching some of your videos in YouTube. You're funny David.  Oh and TALENTED of course!\n",
      "3: I hope everyone had a great weekend! I will be here on and off today as I have 2 important meetings today\n",
      "4: @tenuousness: aoh is one of the best bands. they played my frosh, i was stoked. i have to work tonight, or else i'd totally be there!\n",
      "5: @cydonian why? i enjoy fancy meals on my own smtimes, thr's joy in solitude, u can REALLY enjoy the food &amp; it's lk a date with the world\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'hate': 1323\n",
      "Percentage of the dataset: 3.3075\n",
      "Random indices: [884, 901, 456, 289, 858]\n",
      "\n",
      "Random 5 Tweets for emotion 'hate':\n",
      "1: @velvetella Hey! Polka dots or black dress. Both very glam. Mobile twitter's a bit crap at the mo.\n",
      "2: My new site is stuck in the Google sandpit now  Test of my skills until it comes back out!\n",
      "3: Shit. My friend's in such a state and I don't know how to help him. Nothing I say seems to be helping and I wish I knew what to say\n",
      "4: ow, I just rolled over my toe with my desk chair.\n",
      "5: @Skittles3640 No prob, skittles we always gonna have yall's backs. The true sweeties dont play.. LOL But yea we just got heated. We sry\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'love': 3842\n",
      "Percentage of the dataset: 9.605\n",
      "Random indices: [1057, 3392, 1222, 2689, 3219]\n",
      "\n",
      "Random 5 Tweets for emotion 'love':\n",
      "1: @utterhip Good morning to you, however it's night time for me, so I am off to bed *hugs* Have a great day\n",
      "2: Spending a wonderful Mothers Day with Brad, Mom and Dad.  Happy Mothers Day to all Moms\n",
      "3: is going to be in Texas in 15 days!!! eeekkkk!!!\n",
      "4: @stompthewalrus yay! now ill shall take your picture, and get a tattoo on my arm\n",
      "5: @ZnaTrainer Ahhh Music to my ears!\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'neutral': 8638\n",
      "Percentage of the dataset: 21.595\n",
      "Random indices: [3805, 2206, 8510, 244, 7171]\n",
      "\n",
      "Random 5 Tweets for emotion 'neutral':\n",
      "1: @unclelarko not sure I like this way to learn a new language  I prefer to be &quot;on location&quot;, so I can practice, ask Qs and get answers\n",
      "2: @RhChestnut .. Guess ol' Tom has another mission impossible ... some of this is like trying to prove innocence .. I didn't get hugged\n",
      "3: @nelsonsito Hi fellow Peruvian\n",
      "4: @CheetahmamiBia oooo ok   why  havent you accepted my friends request\n",
      "5: @ginogagaza awww! you like anne curtis too tho rite?? it's her soap thats gonna replace it!\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'relief': 1526\n",
      "Percentage of the dataset: 3.8150000000000004\n",
      "Random indices: [1238, 79, 785, 618, 1079]\n",
      "\n",
      "Random 5 Tweets for emotion 'relief':\n",
      "1: my legs are soft  watching a move with my mommm short day @ workk\n",
      "2: Off for a loooong weekend of inlawing...  ... ...\n",
      "3: is now at school! About to take the ECAs, &quot;LAME!&quot; (Steal from Brennan) Good Job LC and you too Brennan!\n",
      "4: @suziperry Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx\n",
      "5: @SinnamonLove Yes we did!  Thank You!!\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'sadness': 5165\n",
      "Percentage of the dataset: 12.9125\n",
      "Random indices: [1147, 118, 3306, 4283, 4295]\n",
      "\n",
      "Random 5 Tweets for emotion 'sadness':\n",
      "1: Shopped til i dropped....come bac sunshine i miss u\n",
      "2: misses my baby.\n",
      "3: Just heard a single i had been waiting MONTHS to hear....and...im disappointed.\n",
      "4: sometimes i forget my favorite porn stars are real people too. @bobbyclarkxxx made orange chicken last night and cut his finger off! sad!\n",
      "5: feelin depressed ,, i miss you soo damn fcking much besties  ..i wish i wouldnt have left yt\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'surprise': 2187\n",
      "Percentage of the dataset: 5.4675\n",
      "Random indices: [1021, 235, 1571, 679, 292]\n",
      "\n",
      "Random 5 Tweets for emotion 'surprise':\n",
      "1: @jinime Your schmoo is moving? Are you sad?\n",
      "2: i have sore throat. that's suck.\n",
      "3: @KarlosFarrar check out review for the movie Fighting - http://bit.ly/Fle9j  Hilarious!! leave this guy a comment!\n",
      "4: Waaah! Masseuse is fully booked. No shoulder rub today.\n",
      "5: @mynameisgay You are so lucky you get to travel.\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n",
      "Number of tweets for 'worry': 8459\n",
      "Percentage of the dataset: 21.1475\n",
      "Random indices: [8151, 2235, 151, 3844, 4252]\n",
      "\n",
      "Random 5 Tweets for emotion 'worry':\n",
      "1: @Gardenwiseguy This is truly enlightening for me\n",
      "2: My back hurts and I'm meant to be going out tonight, poor the Rik\n",
      "3: finished sewing for the night, uploading pictures from slidebar and beach. i cant believe i am having difficulties with twitter!\n",
      "4: I have one less follower  That makes me sad and I feel like my life is dull and uninteresting.\n",
      "5: @ego_assassin @slinka sucks about your cat... hope you guys feel better\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this cell prints all of the sentiments all at once,\n",
    "# but keeping it commented out for now\n",
    "\n",
    "# for emotion in all_sentiments:\n",
    "#     explore(emotion)\n",
    "#     print('**********************************************************\\n**********************************************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'anger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'anger': 110\n",
      "Percentage of the dataset: 0.27499999999999997\n",
      "Random indices: [102, 34, 11, 27, 106]\n",
      "\n",
      "Random 5 Tweets for emotion 'anger':\n",
      "1: @roberto121 that's some serious shit steve. why didn't you send me pictures or call me!! You know i love a good yard sale.\n",
      "2: @cindaxo the straightener's another 110 pounds though. Seems pricey\n",
      "3: i hav a chance to win $10, $100, $1000.  i was given a free can of $ plant..have to wait till the plant grow to know if i won anythin!!?!\n",
      "4: has a VERY arduous task to accomplish at work...stuff that should have already been done &amp; as usual it hasn't. Not because of me either.\n",
      "5: I'm way to sleepy.. Ill watch my shows lata..Good nite twit-fam!.. God bless!..XoXo\n"
     ]
    }
   ],
   "source": [
    "explore('anger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'anger':\n",
    "\n",
    "The number of 'anger' tweets, 110, is the lowest count in the dataset and represents just 0.2750% of the dataset. This will lead to an imbalance issue.<br>\n",
    "<br>\n",
    "Some of these Tweets seem to be mislabeled (e.g. \"omg! goooood ass nappy nap  jusss woke up bout 2 clean up a lil then get ready\", \"OIL IS CHANGED!  And I am filthy.    But it's an accomplished filthy.\", \"Just sittin here waitin for my coffee to be full grown on farm town before going to bed\"). But most seem to be labeled correctly (e.g. \"What did I do to you!  sheesh\", \"The &quot;Catch Me If You Can&quot; DVD that I rented from Blockbuster.com yesterday was cracked. Figured it out about 35 minutes into the movie.\", \"@drakesizzle  If you don't want to come then don't come. JEEEEEZ.\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'boredom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'boredom': 179\n",
      "Percentage of the dataset: 0.4475\n",
      "Random indices: [16, 48, 126, 61, 14]\n",
      "\n",
      "Random 5 Tweets for emotion 'boredom':\n",
      "1: just woke up day off and need to go in to work that sucks. Also have to go dentist for filling at 12 then st helens for mri scan at 2\n",
      "2: Can't believe how gorgeous the weather has been today &amp; I've had to spend it at work!\n",
      "3: @xx_Megan_xx Same! Like the kisses on nights when she wasnt up for eviction! They were very badly edited\n",
      "4: Wow, kinda bothered that Jon is doing deposits now.  Apparently he keeps getting fucked out of times, but deposits are SO hard for me\n",
      "5: Last Chemistry lesson for this school year!  On a brighter note, my birthday will be sandwiched between two days in chemistry lab!\n"
     ]
    }
   ],
   "source": [
    "explore('boredom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'boredom':\n",
    "\n",
    "This is the second lowest sentiment category with only 179 Tweets representing 0.4475% of the dataset. Like anger, this will be an imbalance issue.<br>\n",
    "<br>\n",
    "The interpretation of 'bored' seems to vary from the traditional sense (e.g. \"I am sooooooo bored in textiles !\", \"is bored. my BFF doesn't want to hang out\") to \"this person must be bored because they have nothing better to do than write this Tweet\" (e.g. \"aw now where's that little asian girl who runs round pooping her pants in public? i miss laughing at her.\", \"my neighbours are far too loud in thier back garden, all I can hear is this loud woman that won't stop laughing\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'empty': 827\n",
      "Percentage of the dataset: 2.0675\n",
      "Random indices: [662, 156, 216, 613, 824]\n",
      "\n",
      "Random 5 Tweets for emotion 'empty':\n",
      "1: Getting ready to go to the comedy club and listening to some Q-Tip  Who's on iChat or Skype right now? I need an outfit critique\n",
      "2: FML i just spilled my entire can of diet coke IN MY LAP. yay\n",
      "3: gotta do my ewrt outline then tennis then work.. i need more time\n",
      "4: @sroxy good morning...did you break 5 digits yet?\n",
      "5: @sloanyxxx Thanks\n"
     ]
    }
   ],
   "source": [
    "explore('empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'empty'\n",
    "\n",
    "It seems that the 'empty' sentiment is very random. At times, there are two or more sentiments expressed (e.g. \"back from grimsby  it sucks bein back but was amazin wknd anyway!!\"). Other times they are just statements of fact or questions (e.g. \"On the way to santa monica\", \"@spook68 morning.any plans for today?\"). Still other times they are just words (\"HELLOO\"). Sometimes, there are Tweets that seem like they should be labeled with one of the other emotions (e.g. \"yay, joss is coming over on saturday\" should probably be labeled 'happiness' or 'enthusiasm') and perhaps because there are possibly two different labels in that last example, the labeler chose to leave it empty.<br>\n",
    "<br>\n",
    "There are 827 of the 'empty' Tweets representing 2.0675% of the dataset. We should consider removing these from the dataset since these seem to be the \"unknown\" type of Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'enthusiasm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'enthusiasm': 759\n",
      "Percentage of the dataset: 1.8975\n",
      "Random indices: [167, 181, 400, 742, 697]\n",
      "\n",
      "Random 5 Tweets for emotion 'enthusiasm':\n",
      "1: @mitchelmusso I want to call you but it would cost to much  But Maybe my parents will say okay =D\n",
      "2: I wanna talk to Mitchel Mussoooooo\n",
      "3: @DavidArchie Hope you find a nice and healthy, also cheap, breakfast!\n",
      "4: Early bird gets the worm.  And in my case, birder gets to witness the carnage.\n",
      "5: @mitsuhiko Np mate, was great meeting you in Prague\n"
     ]
    }
   ],
   "source": [
    "explore('enthusiasm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'enthusiasm':\n",
    "\n",
    "These set of Tweets also suffer from some mislabeling issues (e.g. \"I'm bored, extremely bored. in the car. waiting for my dad. and dinner. chinese. yummm.\", \"wishes I could be the one going to our conference in the Bahamas next week\"). Some Tweets seemed to be mislabeled as 'enthusiasm' due to certain keywords (e.g. \"I made my parents add u guys on the family myspace...they were impressed by the song\" -- 'impressed') or perhaps the number of exclamantion points (e.g. \"im so new!! and i need ur help\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'fun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'fun': 1776\n",
      "Percentage of the dataset: 4.44\n",
      "Random indices: [1565, 608, 840, 256, 591]\n",
      "\n",
      "Random 5 Tweets for emotion 'fun':\n",
      "1: @BB517 sounds like a plan.....yea excited now\n",
      "2: Download movie  &quot;Jackass 3&quot; http://tinyurl.com/caotku cool #movie\n",
      "3: Hahaha @Jordan23Capp yes dey dooo, BOSTON Legal  tha fat old man is funny, tha one that was naked ina pink gown Lol\n",
      "4: everyone vote for @mileycyrus for the mtv movie awards coz my comp is mashed up and wont let me vote!  i will somehow!!!!!!\n",
      "5: @Punisher5463 You Got Twitter! Yayy  xxx\n"
     ]
    }
   ],
   "source": [
    "explore('fun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'fun':\n",
    "\n",
    "This emotion is a bit hard to nail down in terms of what the labelers were going. And, as in other emotions, it seems that there are a lot of mislabeled Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'happiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'happiness':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'hate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('hate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'hate':\n",
    "\n",
    "There are 1132 Tweets labeled 'hate'. They seem to strongly resemble 'anger' and can possibly be relabeled as such. In so doing, we would increase the number of 'anger' Tweets to help with the imbalance issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'love':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'neutral':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'relief'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('relief')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'relief':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('sadness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'sadness':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('surprise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'surprise':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'worry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore('worry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'worry':\n",
    "\n",
    "Have not gotten to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General thoughts about the contents of these tweets:\n",
    "\n",
    "There are @mentions, URLs, and character entities (\"\\&nbsp;\", \"\\&quot;\", \"\\&amp;\") that we may want to remove as part of data cleaning since they are superfluous in terms of indicating emotion. There are also hashtags that we may or may not consider removing. Some of these hashtags don't actually add to the sentiment, but some do so we may consider keeping them.<br>\n",
    "<br>\n",
    "Additionally, there are multiple emotions that have a proportionally small amount of records when compared to others ('anger' with 110 records and 'neutral' with 8638). We will have to deal with this somehow, perhaps by using stratified sampling techniquest (https://stackoverflow.com/questions/70849127/training-validation-and-test-sets-for-imbalanced-datasets-in-machine-learning) rather than a random train/test/validation split which may overrepresent the 'neutral' emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4 Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any @mentions from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove @mentions from the 'content' column\n",
    "df['content'] = df['content'].str.replace(r'@\\w+', '')\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any whitespace from the front and end of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.strip()\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
