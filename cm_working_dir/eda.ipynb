{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9rigx9lYp0r"
   },
   "source": [
    "***\n",
    "# EDA for tweet_emotions.csv dataset\n",
    "https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1 Load the dataset\n",
    " <span style=\"color:red\">!!!Make sure to comment out the correct source (Google drive or local)!!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9j2cEQQtYMBR",
    "outputId": "6f2ae201-8489-40f7-cefd-8d0715350d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
      "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# read from the google drive\n",
    "# url = 'https://drive.google.com/file/d/1xv5hff4DntWz6gn4KMXkBQ6t5_Vs16MQ/view?usp=sharing'\n",
    "# url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "# read from local\n",
    "url = '../datasets/tweet_emotions.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2 Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes for each of the columns in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id      int64\n",
      "sentiment    object\n",
      "content      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique types and count of sentiments in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count  percentage\n",
      "neutral      8638     21.5950\n",
      "worry        8459     21.1475\n",
      "happiness    5209     13.0225\n",
      "sadness      5165     12.9125\n",
      "love         3842      9.6050\n",
      "surprise     2187      5.4675\n",
      "fun          1776      4.4400\n",
      "relief       1526      3.8150\n",
      "hate         1323      3.3075\n",
      "empty         827      2.0675\n",
      "enthusiasm    759      1.8975\n",
      "boredom       179      0.4475\n",
      "anger         110      0.2750\n"
     ]
    }
   ],
   "source": [
    "# get the value counts of each unique value\n",
    "counts = df['sentiment'].value_counts()\n",
    "\n",
    "# convert the counts to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "cp_df = pd.DataFrame({'count': counts, 'percentage': percentages})\n",
    "\n",
    "print(cp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max and min lengths of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length: 167\n",
      "Minimum length: 1\n"
     ]
    }
   ],
   "source": [
    "lengths = df['content'].str.len()\n",
    "\n",
    "# display the maximum and minimum lengths\n",
    "print('Maximum length:', lengths.max())\n",
    "print('Minimum length:', lengths.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3 Check each sentiment to see what type of content there is to see if it's legit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to explore the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(emotion=None):\n",
    "    if emotion == None:\n",
    "        return 'no emotion provided'\n",
    "    elif emotion not in all_sentiments:\n",
    "        return 'not one of the sentiments in the dataframe'\n",
    "    else:\n",
    "        content = df.loc[df['sentiment'] == emotion, 'content']\n",
    "\n",
    "        random_nums = random.sample(range(len(content)), 5)\n",
    "        print(f\"Number of tweets for '{emotion}': {len(content)}\")\n",
    "        print(f\"Percentage of the dataset: {cp_df.loc[emotion].percentage}\")\n",
    "        print(f\"Random indices:' {random_nums}\", end='\\n\\n')\n",
    "        print(f\"Random {len(random_nums)} Tweets for emotion '{emotion}':\")\n",
    "\n",
    "        counter = 1\n",
    "        for tweet in content.iloc[random_nums]:\n",
    "            print(f\"{counter}: {tweet}\", end='\\n')\n",
    "            counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'boredom', 'empty', 'enthusiasm', 'fun', 'happiness', 'hate', 'love', 'neutral', 'relief', 'sadness', 'surprise', 'worry']\n"
     ]
    }
   ],
   "source": [
    "all_sentiments = sorted(df['sentiment'].unique())\n",
    "print(all_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell prints all of the sentiments all at once,\n",
    "# but keeping it commented out for now\n",
    "\n",
    "# unique_sentiments = df['sentiment'].unique()\n",
    "\n",
    "# for emotion in unique_sentiments:\n",
    "#     explore(emotion)\n",
    "#     print('**********************************************************\\n**********************************************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'anger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'anger': 110\n",
      "Percentage of the dataset: 0.27499999999999997\n",
      "Random indices:' [65, 103, 54, 69, 2]\n",
      "\n",
      "Random 5 Tweets for emotion 'anger':\n",
      "1: @JennyTaylor94  yer it is...poor little cock  but she well doesnt deserve the stick off everyone! cowell once again going against producer\n",
      "2: @brainofdane DUDE.  You're a hax0r!!!1!  You should put Final Cut Pro on there and tell me how stable it is\n",
      "3: People at work are stressing me out.\n",
      "4: @natss91 kill me as soon as you get here ,ok? my sister is having a sleepover tonight  and her obnoxious friends are driving me insane\n",
      "5: Packing  I don't like it..\n"
     ]
    }
   ],
   "source": [
    "explore('anger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'anger':\n",
    "\n",
    "The number of 'anger' tweets, 110, is the lowest count in the dataset and represents just 0.2750% of the dataset. This will lead to an imbalance issue.<br>\n",
    "<br>\n",
    "Some of these Tweets seem to be mislabeled (e.g. \"omg! goooood ass nappy nap  jusss woke up bout 2 clean up a lil then get ready\", \"OIL IS CHANGED!  And I am filthy.    But it's an accomplished filthy.\", \"Just sittin here waitin for my coffee to be full grown on farm town before going to bed\"). But most seem to be labeled correctly (e.g. \"What did I do to you!  sheesh\", \"The &quot;Catch Me If You Can&quot; DVD that I rented from Blockbuster.com yesterday was cracked. Figured it out about 35 minutes into the movie.\", \"@drakesizzle  If you don't want to come then don't come. JEEEEEZ.\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'boredom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'boredom': 179\n",
      "Percentage of the dataset: 0.4475\n",
      "Random indices:' [114, 95, 147, 1, 122]\n",
      "\n",
      "Random 5 Tweets for emotion 'boredom':\n",
      "1: J Ross you can't leave the killers still singing and run the titles - you should have been edited out for more music - happy - not\n",
      "2: ya know why today sucks? its been raining, we have no $, &amp; no possibility of a magic friday.  so whats goin down tonight?\n",
      "3: Stuck on NJ Transit for the past twenty minutes. Great way to start the week\n",
      "4: Waiting in line @ tryst\n",
      "5: Just got home from the BEA &amp; it was kinda boring (2 me) this year  but hung out with some GREAT authors &amp; co-workers!\n"
     ]
    }
   ],
   "source": [
    "explore('boredom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'boredom':\n",
    "\n",
    "This is the second lowest sentiment category with only 179 Tweets representing 0.4475% of the dataset. Like anger, this will be an imbalance issue.<br>\n",
    "<br>\n",
    "The interpretation of 'bored' seems to vary from the traditional sense (e.g. \"I am sooooooo bored in textiles !\", \"is bored. my BFF doesn't want to hang out\") to \"this person must be bored because they have nothing better to do than write this Tweet\" (e.g. \"aw now where's that little asian girl who runs round pooping her pants in public? i miss laughing at her.\", \"my neighbours are far too loud in thier back garden, all I can hear is this loud woman that won't stop laughing\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'empty': 827\n",
      "Percentage of the dataset: 2.0675\n",
      "Random indices:' [801, 705, 576, 259, 231]\n",
      "\n",
      "Random 5 Tweets for emotion 'empty':\n",
      "1: @rssanborn games? Just wanted to clarify\n",
      "2: @AnointedPromise Yes, have to be right for church\n",
      "3: Making Banana Bread\n",
      "4: Woke up... cleaned... Aunt Emmas... Walmart.. Commissary... Now its time for a nap!!!.. then off to work\n",
      "5: this is absurd ! I feel like a dipping in the pool real quick . its too bad i dont have a poool\n"
     ]
    }
   ],
   "source": [
    "explore('empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'empty'\n",
    "\n",
    "It seems that the 'empty' sentiment is very random. At times, there are two or more sentiments expressed (e.g. \"back from grimsby  it sucks bein back but was amazin wknd anyway!!\"). Other times they are just statements of fact or questions (e.g. \"On the way to santa monica\", \"@spook68 morning.any plans for today?\"). Still other times they are just words (\"HELLOO\"). Sometimes, there are Tweets that seem like they should be labeled with one of the other emotions (e.g. \"yay, joss is coming over on saturday\" should probably be labeled 'happiness' or 'enthusiasm') and perhaps because there are possibly two different labels in that last example, the labeler chose to leave it empty.<br>\n",
    "<br>\n",
    "There are 827 of the 'empty' Tweets representing 2.0675% of the dataset. We should consider removing these from the dataset since these seem to be the \"UNK\" type of Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'enthusiasm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'enthusiasm': 759\n",
      "Percentage of the dataset: 1.8975\n",
      "Random indices:' [510, 502, 718, 475, 87]\n",
      "\n",
      "Random 5 Tweets for emotion 'enthusiasm':\n",
      "1: @youngscraphics - I produce/direct/film/edit... I write... I coordinate events... I manage Don Fetti... there ain't much I don't do!\n",
      "2: Boredddddd Follower @meryreino Shes AMAZING!!  *Broken*\n",
      "3: did some more work on Dig Dug. can get to level 16 without dying now  Mega Man tomorrow after work. Goal: 2 levels in 5 minutes\n",
      "4: ....dont act like your not impressed\n",
      "5: @xac Reminders are good! Speaking of which, we haven't had a Posture Check in awhile.....\n"
     ]
    }
   ],
   "source": [
    "explore('enthusiasm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'enthusiasm':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'fun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'fun': 1776\n",
      "Percentage of the dataset: 4.44\n",
      "Random indices:' [182, 1261, 429, 1175, 146]\n",
      "\n",
      "Random 5 Tweets for emotion 'fun':\n",
      "1: 4 more days until my birthday!!! I don't want to get older\n",
      "2: @barrysma NEW motorcycle and you POPPED a cable already? wow-you ride HARD!\n",
      "3: @MariaV_ST vaca!! buuu sigo en el work\n",
      "4: bowling with cousins  awesome\n",
      "5: Its 4.30am, sleep timeee. I wanted to watch Gossip Girl but i'm way too tired  Goodnight!\n"
     ]
    }
   ],
   "source": [
    "explore('fun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'fun':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'happiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'happiness': 5209\n",
      "Percentage of the dataset: 13.0225\n",
      "Random indices:' [4534, 3046, 1136, 825, 27]\n",
      "\n",
      "Random 5 Tweets for emotion 'happiness':\n",
      "1: @XKookie03 whyyyy hellloooo! Thx 4 checkin up on me  how r things? http://myloc.me/G4p\n",
      "2: loven the rs ftw pvp is bac\n",
      "3: @kyleandjackieo what about Your Body by Tom Novy or Voodoo Child by Rogue Traders. They are from 04/05. Good memories from these songs\n",
      "4: @ToxicSociopath awww. well before we know it youll be back visiting XD we will hang out constantly and have another heartbreaking goodbye\n",
      "5: @wedplanworkshop . Flights already booked, plus its GGD2 1st birthday. Can't miss that ! especially as we missed GGD1\n"
     ]
    }
   ],
   "source": [
    "explore('happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'happiness':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'hate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'hate': 1323\n",
      "Percentage of the dataset: 3.3075\n",
      "Random indices:' [299, 852, 657, 494, 129]\n",
      "\n",
      "Random 5 Tweets for emotion 'hate':\n",
      "1: TGIF I don't like 12 hour workdays  I need to stand up, run around 4 a while.... too much sitting!!! Plus, I have honest ade tea 2day! YAY\n",
      "2: boredddddddd, work tomorrow..  and sunday. i hate clarks\n",
      "3: @kmrasmussen nah. How it sucks to wear a suit and how the temp goes up 10 degrees when someone sits next to you\n",
      "4: DIDO &quot;US 2 Little Gods&quot; http://ow.ly/9UIn &quot;Just this moment/ Let it all stop here/ I've had my fill&quot;...words that make you panic...\n",
      "5: @GGSerena boo you didnt answer my text\n"
     ]
    }
   ],
   "source": [
    "explore('hate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'hate':\n",
    "\n",
    "There are 1132 Tweets labeled 'hate'. They seem to strongly resemble 'anger' and can possibly be relabeled as such. In so doing, we would increase the number of 'anger' Tweets to help with the imbalance issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'love': 3842\n",
      "Percentage of the dataset: 9.605\n",
      "Random indices:' [2804, 1056, 296, 89, 2314]\n",
      "\n",
      "Random 5 Tweets for emotion 'love':\n",
      "1: I love my life  Ni night twitter!&lt;3\n",
      "2: Done with HW...gonna read a bit then pass out. Got a cool week to look forward too in between all the mayhem\n",
      "3: eating some breakfast at Panera Bread. boring cloudy weather, lil drizzle\n",
      "4: @melissaohh omg  when do they finish??\n",
      "5: @oreoking awe thanks\n"
     ]
    }
   ],
   "source": [
    "explore('love')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'love':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'neutral': 8638\n",
      "Percentage of the dataset: 21.595\n",
      "Random indices:' [2738, 4214, 6369, 2699, 1746]\n",
      "\n",
      "Random 5 Tweets for emotion 'neutral':\n",
      "1: gymnastics time.  My last night for teaching Friday evening classes.   New summer schedule starts next week.\n",
      "2: @WKJThD  Thanks for Following\n",
      "3: @dhgarske ha. nothing any man does is right on mothers day except for taking kids off mum's hands for whole day\n",
      "4: cof Cof Cof!\n",
      "5: No... have to go on cruches next 2 weeks\n"
     ]
    }
   ],
   "source": [
    "explore('neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'neutral':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'relief'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'relief': 1526\n",
      "Percentage of the dataset: 3.8150000000000004\n",
      "Random indices:' [1051, 460, 485, 539, 216]\n",
      "\n",
      "Random 5 Tweets for emotion 'relief':\n",
      "1: @StorySeeker lol...but they aren't here! I'll tell them to do that Monday. lol\n",
      "2: i finished new moon  in 1 day all up. maybe less, im quite proud, now who wants to lend me eclipse haha\n",
      "3: Finally sleep time\n",
      "4: Morning world! back to the office after longgggggggg weekend\n",
      "5: Andrew's flight back to CO should be landing soon\n"
     ]
    }
   ],
   "source": [
    "explore('relief')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'relief':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'sadness': 5165\n",
      "Percentage of the dataset: 12.9125\n",
      "Random indices:' [5141, 3288, 1590, 1485, 4864]\n",
      "\n",
      "Random 5 Tweets for emotion 'sadness':\n",
      "1: my back and legs kill from yesterday and we have a big old leak in the kitchen, looks like staying in pjs all day infront of the tv\n",
      "2: @siirensiiren meagan rochelle &quot;the one u need&quot; i would say &quot;cater 2 u&quot; by he didnt produce that.\n",
      "3: @MouseGoesSqueak ahhhh.same here with Geometry, like i said b4, if i didn't have it, i would be graduated!! so i feel ur pain hun!\n",
      "4: @xxxmaggie oh that sucks  I'm sorry.\n",
      "5: @sharkattack44 i wish there was an &quot;i like&quot; option (like fb) for things like this\n"
     ]
    }
   ],
   "source": [
    "explore('sadness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'sadness':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'surprise': 2187\n",
      "Percentage of the dataset: 5.4675\n",
      "Random indices:' [1480, 1909, 892, 984, 1328]\n",
      "\n",
      "Random 5 Tweets for emotion 'surprise':\n",
      "1: Somehow my alarm became an hour fast and I came to realize it as I was leaving the house.. It feels good having an early start\n",
      "2: Going to bed, stores are closed\n",
      "3: @ClaudeKelly What day is it? What's #FF? I'm worst than you\n",
      "4: @missuzliipzlive ilooked in my phone book and ur name was the first to show and i was like i got ti-ti number but it was just ur email\n",
      "5: @RobHolladay I added it, are you still awake?\n"
     ]
    }
   ],
   "source": [
    "explore('surprise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'surprise':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore 'worry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets for 'worry': 8459\n",
      "Percentage of the dataset: 21.1475\n",
      "Random indices:' [555, 6361, 4951, 3091, 5957]\n",
      "\n",
      "Random 5 Tweets for emotion 'worry':\n",
      "1: I want to ride my bicycle today, but it's too cold and cloudy today\n",
      "2: @jenniclarephoto Sometimes (although I usually go willingly  ) Don't know about the Churnet Valley event though.\n",
      "3: @Impala_Guy Me neither  But itï¿½s getting better\n",
      "4: Life Just Isn't Fair &gt; And I Feel\n",
      "5: @selenagomez AWWWE! I live in Van, would've been so great to see you  but have a great flight!\n"
     ]
    }
   ],
   "source": [
    "explore('worry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial thoughts on 'worry':\n",
    "\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General thoughts about the contents of these tweets:\n",
    "\n",
    "There are @mentions, URLs, and character entities (\"\\&nbsp;\", \"\\&quot;\", \"\\&amp;\") that we may want to remove as part of data cleaning since they are superfluous in terms of indicating emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any @mentions from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty   i know  i was listenin to bad habit earlier a...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
      "4  1956968416     neutral   We want to trade with someone who has Houston...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/1dx552ps4m9367dbldkwdp0h0000gn/T/ipykernel_27675/3023358060.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'@\\w+', '')\n"
     ]
    }
   ],
   "source": [
    "# remove @mentions from the 'content' column\n",
    "df['content'] = df['content'].str.replace(r'@\\w+', '')\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data by removing any whitespace from the front and end of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty  i know  i was listenin to bad habit earlier an...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
      "4  1956968416     neutral  We want to trade with someone who has Houston ...\n"
     ]
    }
   ],
   "source": [
    "df['content'] = df['content'].str.strip()\n",
    "\n",
    "# display the resulting DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
